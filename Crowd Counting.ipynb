{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CIoVhmS0LYF_"
   },
   "source": [
    "# Crowd Counting: Count the Number of Customers Appeared in the Business"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GNS9x1pcUuuU"
   },
   "source": [
    "![Imgur](https://i.imgur.com/r1U9dHD.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YP7NG6txPfj0"
   },
   "source": [
    "##**Scenario**\n",
    "\n",
    ">\"We see our customers as invited guests to a party, and we are the hosts. It’s our job every day to make every important aspect of the customer experience a little bit better.\"   **--- Jeff Bezos, Amazon CEO**\n",
    "\n",
    "\n",
    "\n",
    "This is also true for all brick-and-motor stores at shopping malls. As a host, one thing you definitely should know is: *How many `guests` are attending your `party`*.\n",
    "\n",
    "The #(sign for quantity) of customers are curcial. Key factors for a successful business include `store rent`, `store sales`, which are all strongly correlated with `customers quantity`. \\\n",
    "\n",
    "\n",
    "\n",
    "In Practice, keeping track of passenger flow or customer traffic is never an easy thing. At the old times, customers are counted manually. Later, sensors are installed at the entrance, which provide a higher-accuracy solution, but suffers from high cost (Just imagine how many sensors should be installed). \\\n",
    "\n",
    "Not all malls have the luxury of installing sensors, but all malls have video surveillance cameras. With the images captured by real-time cameras, computer vision technology can help counting customers 24/7.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oJmLiXxsL2mE"
   },
   "source": [
    "<img src=\"https://storage.googleapis.com/kaggle-datasets-images/526740/966025/1b806f39569b1157b1aaafe81f59f4b6/dataset-cover.jpg?t=2020-02-24-06-34-25\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0eWOFA4hUk5e",
    "outputId": "f8f4b4ac-2e0b-4aee-d06d-4bf32d452925"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "#This step is done to connect the content directory to Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wEJko_TaKWCx"
   },
   "source": [
    "## **Task**\n",
    "Build a neural network to count the number of customers appeared in the image captured so we can understand the potential customers.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AlpW9nv_VmRn"
   },
   "source": [
    "If you would like to download the dataset, please use below link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "h5_0h4NBpYfn"
   },
   "outputs": [],
   "source": [
    "link = 'https://drive.google.com/file/d/1RwuuNLpQWcozMOGw6Fp42m_dIhuqH90y/view?usp=sharing' # The shareable link\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AYQ4mzCUjGa_"
   },
   "source": [
    "### Unzip the data file\n",
    "<font color=\"orange\"><b>Todo:</b></font>\\\n",
    "Replace the `PATH_TO_ZIP_FILE` with the path to your data file in your Google Drive. We are unzipping the data file to the `/content/crowd-counting` directory, which won't use your Google Drive storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "i5J44W3iEJ8a"
   },
   "outputs": [],
   "source": [
    "!unzip -q \"/content/drive/MyDrive/DAT565E/Individual 3/Crowd_counting_dataset.zip\" -d /content/crowd-counting # you should use your own link for the zip file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LbwYWP5dtW4e"
   },
   "source": [
    "### Load csv files and train-test-split\n",
    "<font color=\"orange\"><b>Todo:</b></font>\\\n",
    "(1) Read `/content/crowd-counting/labels.csv`: Read csv files as `Pandas DataFrame` into RAM\\\n",
    "(2) Use `Pandas` API, create a new column named `dir`, which stores the image file names. \\\n",
    "(3) Split the whole data into `training dataframe` (0.7) and `testing dataframe` (0.3)\\\n",
    "(4) Split the above `testing dataframe` into `testing dataframe`(0.5) and `validation dataframe` (0.5)\\\n",
    "Hint: Try to think about the relationship between the number above and the \"?\" parameters below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "RnZyjdxjVIZD"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"/content/crowd-counting/labels.csv\")\n",
    "X=\"dir\"\n",
    "Y=\"count\"\n",
    "df[X]=\"seq_\"+df.id.astype(str).str.zfill(6)+\".jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tx_oEr3PEyrQ",
    "outputId": "6ad436f8-aa6a-4bb1-c5cf-265e742e26a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 3) (300, 3) (300, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Train-test-validation split\n",
    "train,_=train_test_split(df,test_size=0.3)\n",
    "validation,test=train_test_split(_,test_size=0.5)\n",
    "print(train.shape,validation.shape,test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QmK7VSMuy8Uq"
   },
   "source": [
    "**Quick check for your answer:**\\\n",
    "(1400, 3) (300, 3) (300, 3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "AJ0BZlxJYs4y",
    "outputId": "417bdf8d-737e-45b1-fbab-299921d61f97"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df\",\n  \"rows\": 2000,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 577,\n        \"min\": 1,\n        \"max\": 2000,\n        \"num_unique_values\": 2000,\n        \"samples\": [\n          1861,\n          354,\n          1334\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 13,\n        \"max\": 53,\n        \"num_unique_values\": 39,\n        \"samples\": [\n          53,\n          13,\n          27\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dir\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2000,\n        \"samples\": [\n          \"seq_001861.jpg\",\n          \"seq_000354.jpg\",\n          \"seq_001334.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-60d30b1e-4dc6-4391-9eee-40d3635f3184\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>count</th>\n",
       "      <th>dir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>seq_000001.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>seq_000002.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "      <td>seq_000003.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>seq_000004.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>seq_000005.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-60d30b1e-4dc6-4391-9eee-40d3635f3184')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-60d30b1e-4dc6-4391-9eee-40d3635f3184 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-60d30b1e-4dc6-4391-9eee-40d3635f3184');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-ab09b6ba-e09f-4203-8fca-90a785e54333\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ab09b6ba-e09f-4203-8fca-90a785e54333')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-ab09b6ba-e09f-4203-8fca-90a785e54333 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   id  count             dir\n",
       "0   1     35  seq_000001.jpg\n",
       "1   2     41  seq_000002.jpg\n",
       "2   3     41  seq_000003.jpg\n",
       "3   4     44  seq_000004.jpg\n",
       "4   5     41  seq_000005.jpg"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yyAvqUAc26jh"
   },
   "source": [
    "### Configure data generator\n",
    "<font color=\"orange\"><b>Todo:</b></font>\n",
    "\n",
    "Now, let's configure **3** generators: for training, validation, test respectively, in the code chunk below.\n",
    "\n",
    "\\\n",
    "**Note**: \\\n",
    "(1) Simply rescale input to `1./255`.\n",
    "You don't need to perform augmentations such as rotation, zooming, and so on. The reason is that the testing images is exactly the same as training images.\n",
    "\n",
    "(2) Here's a very helpful link about how to use the `flow_from_dataframe` API\\\n",
    "https://keras.io/api/preprocessing/image/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f5BE0qmJqcJl",
    "outputId": "d4496b15-2790-4ef8-ae14-089a785b0c28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1400 validated image filenames.\n",
      "Found 300 validated image filenames.\n",
      "Found 300 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "\n",
    "target_size = (120, 160)\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_gen = train_datagen.flow_from_dataframe(train,\n",
    "                                              directory='/content/crowd-counting/frames/frames',\n",
    "                                              target_size=target_size,\n",
    "                                              class_mode='raw',\n",
    "                                              x_col=X,\n",
    "                                              y_col=Y,\n",
    "                                              shuffle=True)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_gen = val_datagen.flow_from_dataframe(validation,\n",
    "                                          directory='/content/crowd-counting/frames/frames',\n",
    "                                          target_size=target_size,\n",
    "                                          class_mode='raw',\n",
    "                                          x_col=X,\n",
    "                                          y_col=Y)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_gen = test_datagen.flow_from_dataframe(test,\n",
    "                                            directory='/content/crowd-counting/frames/frames',\n",
    "                                            target_size=target_size,\n",
    "                                            class_mode='raw',\n",
    "                                            x_col=X,\n",
    "                                            y_col=Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0iHD7xap7y5_"
   },
   "source": [
    "**Quick check:**\\\n",
    "The result should be like: \\\n",
    "\n",
    "\n",
    "Found 1400 validated image filenames.\\\n",
    "Found 300 validated image filenames.\\\n",
    "Found 300 validated image filenames.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TBISWTFf8vhP"
   },
   "source": [
    "### Build Model\n",
    "<font color=\"orange\"><b>Todo:</b></font>\\\n",
    "Build your convolutional neural network sequential model.\n",
    "First, build a 2-hidden layer model. Then build a CNN model with 2 convolution layers. Your CNN model should outperform the dense layer model in order to get a full grade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "37z7XX1AThMM"
   },
   "source": [
    "#### Dense Layer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cctkJSYrQkLx",
    "outputId": "746e7401-1716-4d23-f544-029d736aa5e6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 132ms/step - loss: 513.4719 - mae: 14.3043 - val_loss: 50.1779 - val_mae: 5.6895\n",
      "Epoch 2/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 118ms/step - loss: 54.5535 - mae: 5.9812 - val_loss: 42.7021 - val_mae: 5.1438\n",
      "Epoch 3/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 89ms/step - loss: 44.6007 - mae: 5.3340 - val_loss: 43.8463 - val_mae: 5.5300\n",
      "Epoch 4/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 105ms/step - loss: 34.7275 - mae: 4.6656 - val_loss: 38.6993 - val_mae: 4.8624\n",
      "Epoch 5/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - loss: 32.7415 - mae: 4.5522 - val_loss: 24.3025 - val_mae: 3.8521\n",
      "Epoch 6/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 89ms/step - loss: 25.6213 - mae: 4.0172 - val_loss: 46.2823 - val_mae: 5.8020\n",
      "Epoch 7/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 103ms/step - loss: 27.6861 - mae: 4.2633 - val_loss: 18.6848 - val_mae: 3.6217\n",
      "Epoch 8/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - loss: 18.4313 - mae: 3.4478 - val_loss: 14.3648 - val_mae: 3.0792\n",
      "Epoch 9/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - loss: 13.3704 - mae: 2.8890 - val_loss: 12.9816 - val_mae: 2.8977\n",
      "Epoch 10/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 95ms/step - loss: 12.4197 - mae: 2.7718 - val_loss: 13.3625 - val_mae: 3.0379\n",
      "Epoch 11/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - loss: 12.8836 - mae: 2.8379 - val_loss: 13.0253 - val_mae: 2.9943\n",
      "Epoch 12/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - loss: 10.1278 - mae: 2.5537 - val_loss: 9.8840 - val_mae: 2.5099\n",
      "Epoch 13/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 90ms/step - loss: 14.9679 - mae: 3.1046 - val_loss: 11.2716 - val_mae: 2.7467\n",
      "Epoch 14/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 11.3331 - mae: 2.7112 - val_loss: 16.9638 - val_mae: 3.2609\n",
      "Epoch 15/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 11.9825 - mae: 2.7732 - val_loss: 8.7529 - val_mae: 2.3485\n",
      "Epoch 16/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 82ms/step - loss: 8.2994 - mae: 2.3249 - val_loss: 10.1142 - val_mae: 2.5970\n",
      "Epoch 17/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 76ms/step - loss: 9.7776 - mae: 2.5123 - val_loss: 8.5586 - val_mae: 2.2805\n",
      "Epoch 18/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - loss: 7.6794 - mae: 2.2103 - val_loss: 7.9306 - val_mae: 2.2342\n",
      "Epoch 19/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 94ms/step - loss: 7.3372 - mae: 2.1471 - val_loss: 14.2693 - val_mae: 3.0347\n",
      "Epoch 20/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - loss: 8.4083 - mae: 2.3046 - val_loss: 7.3404 - val_mae: 2.1335\n",
      "Epoch 21/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 76ms/step - loss: 6.7063 - mae: 2.0638 - val_loss: 8.1485 - val_mae: 2.2997\n",
      "Epoch 22/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 98ms/step - loss: 7.6452 - mae: 2.2266 - val_loss: 14.1889 - val_mae: 3.1764\n",
      "Epoch 23/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 75ms/step - loss: 10.4903 - mae: 2.6245 - val_loss: 6.9990 - val_mae: 2.0705\n",
      "Epoch 24/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - loss: 5.6165 - mae: 1.8711 - val_loss: 7.0134 - val_mae: 2.0715\n",
      "Epoch 25/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 89ms/step - loss: 7.5054 - mae: 2.1922 - val_loss: 12.6475 - val_mae: 2.9760\n",
      "Epoch 26/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - loss: 7.3996 - mae: 2.2102 - val_loss: 7.6695 - val_mae: 2.1677\n",
      "Epoch 27/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - loss: 5.7492 - mae: 1.8905 - val_loss: 6.4772 - val_mae: 2.0180\n",
      "Epoch 28/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 5.8721 - mae: 1.9557 - val_loss: 6.1504 - val_mae: 1.9448\n",
      "Epoch 29/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 75ms/step - loss: 5.4152 - mae: 1.8525 - val_loss: 6.2791 - val_mae: 1.9927\n",
      "Epoch 30/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 74ms/step - loss: 6.2381 - mae: 1.9808 - val_loss: 6.2048 - val_mae: 1.9372\n",
      "Epoch 31/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 88ms/step - loss: 4.9818 - mae: 1.7610 - val_loss: 28.1259 - val_mae: 4.6357\n",
      "Epoch 32/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - loss: 7.8985 - mae: 2.2031 - val_loss: 11.2939 - val_mae: 2.7341\n",
      "Epoch 33/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - loss: 6.3935 - mae: 2.0365 - val_loss: 13.9138 - val_mae: 3.0479\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7c7978082080>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Pile up layers.\n",
    "dense_model = Sequential()\n",
    "dense_model.add(Flatten(input_shape=(120,160,3)))\n",
    "dense_model.add(Dense(128, activation='relu'))\n",
    "dense_model.add(Dense(64, activation='relu'))\n",
    "dense_model.add(Dense(1))\n",
    "\n",
    "# Compile model\n",
    "dense_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# Fit model.\n",
    "dense_model.fit(train_gen,\n",
    "                validation_data=val_gen,\n",
    "                epochs=50,\n",
    "                callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e45GLjJI-gzX"
   },
   "source": [
    "The following code is provided for you to calculate model mse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1eFg8MKplRG0",
    "outputId": "4cf838f2-88cb-493d-b031-62099ea7a1b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.8784710121154786"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "y = []\n",
    "for i in range(len(test_gen)):\n",
    "    batch = test_gen[i]\n",
    "    y.extend(batch[1])\n",
    "predict = dense_model.predict(test_gen)\n",
    "mean_absolute_error(np.array(y), predict.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9jwfGR0iTr2Q"
   },
   "source": [
    "#### CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D199l868ZUXg"
   },
   "source": [
    "You can use any hyperparameters and improve your results here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UafihDwJQkLx",
    "outputId": "ee3c9882-833c-4584-ab5c-589edf5d7cb4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 154ms/step - loss: 253.6031 - mae: 12.1365 - mape: 40.2579 - val_loss: 54.1358 - val_mae: 5.6086 - val_mape: 18.6211 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 89ms/step - loss: 56.0553 - mae: 5.9420 - mape: 20.3871 - val_loss: 40.9280 - val_mae: 4.8379 - val_mape: 17.1977 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - loss: 40.5429 - mae: 4.9217 - mape: 16.9182 - val_loss: 25.3814 - val_mae: 3.6092 - val_mape: 11.1790 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 85ms/step - loss: 21.6046 - mae: 3.2653 - mape: 11.0557 - val_loss: 16.7760 - val_mae: 2.7999 - val_mape: 9.3840 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - loss: 14.6173 - mae: 2.5104 - mape: 8.4129 - val_loss: 14.4647 - val_mae: 2.5278 - val_mape: 8.1233 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 77ms/step - loss: 14.9838 - mae: 2.5894 - mape: 8.7167 - val_loss: 20.9502 - val_mae: 3.3934 - val_mape: 11.9001 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - loss: 13.7048 - mae: 2.4903 - mape: 8.3795 - val_loss: 12.6248 - val_mae: 2.3243 - val_mape: 7.4093 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 90ms/step - loss: 11.0242 - mae: 2.0873 - mape: 6.9151 - val_loss: 15.5037 - val_mae: 2.7963 - val_mape: 9.8529 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 90ms/step - loss: 11.7833 - mae: 2.2163 - mape: 7.5711 - val_loss: 15.6228 - val_mae: 2.7811 - val_mape: 8.5556 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 90ms/step - loss: 9.6579 - mae: 1.9779 - mape: 6.6259 - val_loss: 12.0121 - val_mae: 2.3378 - val_mape: 8.0641 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - loss: 9.4511 - mae: 1.9782 - mape: 6.6199 - val_loss: 16.1241 - val_mae: 2.9529 - val_mape: 10.3449 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 85ms/step - loss: 10.6320 - mae: 2.2093 - mape: 7.3078 - val_loss: 10.4464 - val_mae: 2.1120 - val_mape: 6.9432 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 91ms/step - loss: 8.2365 - mae: 1.7819 - mape: 5.9289 - val_loss: 10.3655 - val_mae: 2.1258 - val_mape: 7.1895 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - loss: 8.2616 - mae: 1.8050 - mape: 5.8907 - val_loss: 11.1382 - val_mae: 2.2408 - val_mape: 7.0732 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 82ms/step - loss: 8.5597 - mae: 1.8892 - mape: 6.3346 - val_loss: 9.5885 - val_mae: 2.0219 - val_mape: 6.6765 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 86ms/step - loss: 7.7554 - mae: 1.7264 - mape: 5.7702 - val_loss: 9.3269 - val_mae: 2.0002 - val_mape: 6.5811 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 88ms/step - loss: 7.8660 - mae: 1.7467 - mape: 5.8075 - val_loss: 17.9896 - val_mae: 3.3369 - val_mape: 11.8848 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - loss: 9.0559 - mae: 1.9881 - mape: 6.6978 - val_loss: 11.0135 - val_mae: 2.2846 - val_mape: 7.1685 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - loss: 9.4250 - mae: 2.0450 - mape: 6.7683 - val_loss: 9.1843 - val_mae: 1.9960 - val_mape: 6.5852 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 86ms/step - loss: 7.6175 - mae: 1.7601 - mape: 5.7705 - val_loss: 9.3488 - val_mae: 2.0270 - val_mape: 6.5499 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 85ms/step - loss: 6.9646 - mae: 1.6274 - mape: 5.3967 - val_loss: 10.4832 - val_mae: 2.2111 - val_mape: 7.0034 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - loss: 7.0082 - mae: 1.6521 - mape: 5.5250 - val_loss: 9.4253 - val_mae: 2.0470 - val_mape: 6.8820 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - loss: 6.2348 - mae: 1.5014 - mape: 5.0012 - val_loss: 8.6332 - val_mae: 1.9483 - val_mape: 6.3990 - learning_rate: 5.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 85ms/step - loss: 5.7610 - mae: 1.4312 - mape: 4.7565 - val_loss: 8.9275 - val_mae: 2.0146 - val_mape: 6.8205 - learning_rate: 5.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 85ms/step - loss: 5.9096 - mae: 1.4913 - mape: 4.9541 - val_loss: 8.5507 - val_mae: 1.9512 - val_mape: 6.3689 - learning_rate: 5.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 88ms/step - loss: 5.7787 - mae: 1.4373 - mape: 4.8447 - val_loss: 11.1904 - val_mae: 2.3757 - val_mape: 7.4536 - learning_rate: 5.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - loss: 5.7891 - mae: 1.4572 - mape: 4.7975 - val_loss: 9.7854 - val_mae: 2.1394 - val_mape: 6.7549 - learning_rate: 5.0000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - loss: 5.5599 - mae: 1.3937 - mape: 4.6798 - val_loss: 8.3568 - val_mae: 1.9365 - val_mape: 6.3025 - learning_rate: 5.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 86ms/step - loss: 5.0449 - mae: 1.3100 - mape: 4.3720 - val_loss: 8.5510 - val_mae: 1.9842 - val_mape: 6.3902 - learning_rate: 5.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 82ms/step - loss: 6.3527 - mae: 1.6025 - mape: 5.3410 - val_loss: 9.0394 - val_mae: 2.0538 - val_mape: 6.5600 - learning_rate: 5.0000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - loss: 5.3261 - mae: 1.4021 - mape: 4.7089 - val_loss: 8.4844 - val_mae: 1.9757 - val_mape: 6.3772 - learning_rate: 5.0000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - loss: 5.2957 - mae: 1.3751 - mape: 4.5541 - val_loss: 8.6258 - val_mae: 1.9970 - val_mape: 6.4170 - learning_rate: 2.5000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 86ms/step - loss: 4.7759 - mae: 1.2526 - mape: 4.2121 - val_loss: 8.0473 - val_mae: 1.9034 - val_mape: 6.2060 - learning_rate: 2.5000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 88ms/step - loss: 4.9451 - mae: 1.3344 - mape: 4.4405 - val_loss: 7.9549 - val_mae: 1.8851 - val_mape: 6.2588 - learning_rate: 2.5000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - loss: 4.9775 - mae: 1.3353 - mape: 4.4625 - val_loss: 8.0293 - val_mae: 1.9021 - val_mape: 6.2277 - learning_rate: 2.5000e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 85ms/step - loss: 4.5563 - mae: 1.2155 - mape: 4.0834 - val_loss: 7.8030 - val_mae: 1.8601 - val_mape: 6.1683 - learning_rate: 2.5000e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 86ms/step - loss: 4.5080 - mae: 1.2064 - mape: 4.0196 - val_loss: 7.9801 - val_mae: 1.8905 - val_mape: 6.4025 - learning_rate: 2.5000e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 76ms/step - loss: 5.6182 - mae: 1.4908 - mape: 4.9706 - val_loss: 7.7978 - val_mae: 1.8540 - val_mape: 6.1939 - learning_rate: 2.5000e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - loss: 4.6577 - mae: 1.2465 - mape: 4.1692 - val_loss: 7.8587 - val_mae: 1.8847 - val_mape: 6.1831 - learning_rate: 2.5000e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 86ms/step - loss: 4.3780 - mae: 1.1809 - mape: 3.9558 - val_loss: 7.7214 - val_mae: 1.8522 - val_mape: 6.1490 - learning_rate: 2.5000e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 85ms/step - loss: 4.4004 - mae: 1.1986 - mape: 4.0595 - val_loss: 7.9128 - val_mae: 1.8901 - val_mape: 6.1664 - learning_rate: 2.5000e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 89ms/step - loss: 4.3281 - mae: 1.1771 - mape: 3.9422 - val_loss: 8.7187 - val_mae: 2.0273 - val_mape: 6.4618 - learning_rate: 2.5000e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 85ms/step - loss: 4.4441 - mae: 1.2277 - mape: 4.0582 - val_loss: 7.8548 - val_mae: 1.8971 - val_mape: 6.1728 - learning_rate: 2.5000e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - loss: 4.1904 - mae: 1.1473 - mape: 3.8924 - val_loss: 7.7501 - val_mae: 1.8756 - val_mape: 6.1304 - learning_rate: 1.2500e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 91ms/step - loss: 4.1897 - mae: 1.1531 - mape: 3.8240 - val_loss: 7.8664 - val_mae: 1.8962 - val_mape: 6.1592 - learning_rate: 1.2500e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7aae27f0c8e0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "cnn_model = Sequential()\n",
    "# Pile up layers.\n",
    "\n",
    "# Conv+Pool (1)\n",
    "cnn_model.add(Conv2D(30, (3, 3), activation='relu', input_shape=(120, 160, 3), kernel_regularizer=l2(0.01)))\n",
    "cnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#cnn_model.add(Dropout(0.01))\n",
    "\n",
    "# Conv+Pool (2)\n",
    "cnn_model.add(Conv2D(40, (3, 3), activation='relu', kernel_regularizer=l2(0.01)))\n",
    "cnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "cnn_model.add(Dropout(0.02))\n",
    "\n",
    "# Conv+Pool (3)\n",
    "#cnn_model.add(Conv2D(128, (3, 3), activation='relu', kernel_regularizer=l2(0.01)))\n",
    "#cnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#cnn_model.add(Dropout(0.08))\n",
    "\n",
    "cnn_model.add(Flatten())\n",
    "\n",
    "cnn_model.add(Dense(40, activation='relu', kernel_regularizer=l2(0.05)))\n",
    "#cnn_model.add(Dropout(0.06))\n",
    "\n",
    "cnn_model.add(Dense(1))\n",
    "\n",
    "\n",
    "# Compile model\n",
    "cnn_model.compile(optimizer='adam', loss='mse', metrics=['mae', 'mape'])\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "#model_checkpoint = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
    "\n",
    "# Fit model.\n",
    "cnn_model.fit(train_gen,\n",
    "                validation_data=val_gen,\n",
    "                epochs=50,\n",
    "                callbacks=[early_stopping, reduce_lr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JRzcImIaQkLx",
    "outputId": "c3a812ee-d821-4c59-ef1f-4c2f0f586e48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step\n",
      "Validation MAE: 1.8521597131093344\n",
      "Validation MAPE: 6.148969922601193%\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 81ms/step\n",
      "Train MAE: 1.143839567048209\n",
      "Train MAPE: 3.8710151081685025%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "import numpy as np\n",
    "\n",
    "def calculate_mae_mape(model, data_gen):\n",
    "    y_true = []\n",
    "    for i in range(len(data_gen)):\n",
    "        y_true.extend(list(data_gen[i][1]))\n",
    "    y_pred = model.predict(data_gen).flatten()\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred) * 100\n",
    "    return mae, mape\n",
    "mae_val, mape_val = calculate_mae_mape(cnn_model, val_gen)\n",
    "print(f\"Validation MAE: {mae_val}\")\n",
    "print(f\"Validation MAPE: {mape_val}%\")\n",
    "mae_train, mape_train = calculate_mae_mape(cnn_model, train_gen)\n",
    "print(f\"Train MAE: {mae_train}\")\n",
    "print(f\"Train MAPE: {mape_train}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vkdlVp1cYIth"
   },
   "source": [
    "### ***Conclusion and Discussion***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IfHqWPvIz3bA"
   },
   "source": [
    "#### **Question 1: Please explain which kinds of layer is used in your CNN model. What are the functions of those layers? Please explain and interpret your results.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7UT9XfPvYHDO"
   },
   "source": [
    "I used 2 convolutional layers (with pool layers) and 1 dense layer. The convolutional layers take partial features from the input pictures and generate the feature figures. The pooling layers function as undersampling, which decrease the level of feature figures to reduce the dimension but keep the most important features. The dense layer plays the role of \"decisioning\" by learning the weights and combine the features to output the final prediction outcomes. The current result is not ideal. I've tried more than a day of those different parameters. Once I want to add \"Dropout\" or increase the weight of L2, MAPE both increase a lot, and the overfitting problem still exists. Besides, I believe relative lower neurons works better than larger neurons for each layer through all of my tests. The current result shows that the model lacks the generalization, and there is overfitting.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RwAFk7dT02E8"
   },
   "source": [
    "#### **Question 2: Which type of error measure did you use for the model training? How does this kind of error measure defined?**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X2xrY_9vYCTL"
   },
   "source": [
    "I used mae and mape. MAE is the average absolute difference between the prediction and real value. MAPE is the average relative error between the prediction and real value.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JH0pP_vRY8Nr"
   },
   "source": [
    "#### **Question 3: What business problem can be addressed by CNN? Can you give an example?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GFnV45PYZGiu"
   },
   "source": [
    "Self-driving cars maybe can use CNNs for detecting objects, road lanes, sidewalks, and pedestrains on the road."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lrYhlopAm0IZ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
